--- git status ---
HEAD detached from dc9bbf2
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/locomotion_env.py
	modified:   source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/supervised_learning_networks.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	cuncurrent_state_estimator.pth
	tested_policies/hyqreal2/2025-09-08_21-18-56_8k_128_128_128_hyqreal_no_filter_new_friction/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/locomotion_env.py b/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/locomotion_env.py
index 37f2172..1d1076f 100644
--- a/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/locomotion_env.py
+++ b/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/locomotion_env.py
@@ -688,7 +688,8 @@ class LocomotionEnv(DirectRLEnv):
         num_episode_from_start = self.common_step_counter / 24. #self.max_episode_length #HACK this should be taken from rsl rl
         num_final_episode_from_start = 8000.
         if num_episode_from_start > self.cfg.cuncurrent_state_est_ep_saving_interval:
-            prediction_cuncurrent_state_est = self._cuncurrent_state_est_network(obs_cuncurrent_state_est)
+            with torch.no_grad(): 
+                prediction_cuncurrent_state_est = self._cuncurrent_state_est_network(obs_cuncurrent_state_est)
             linear_velocity_b = prediction_cuncurrent_state_est[:, :3]
         else:
             linear_velocity_b = self._robot.data.root_lin_vel_b
@@ -740,7 +741,8 @@ class LocomotionEnv(DirectRLEnv):
         num_episode_from_start = self.common_step_counter / 24. #self.max_episode_length #HACK this should be taken from rsl rl
         num_final_episode_from_start = 8000.
         if num_episode_from_start > self.cfg.rma_ep_saving_interval:
-            prediction_rma = self._rma_network(obs)
+            with torch.no_grad(): 
+                prediction_rma = self._rma_network(obs)
             obs_rma = prediction_rma
         else:
             obs_rma = outputs_rma
diff --git a/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/supervised_learning_networks.py b/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/supervised_learning_networks.py
index 35b937f..5d97c40 100644
--- a/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/supervised_learning_networks.py
+++ b/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/supervised_learning_networks.py
@@ -124,6 +124,8 @@ class SimpleNN(torch.nn.Module):
                         optimizer.step()
     
                     print(f"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}")
+        self.eval()
+        print("Training complete. Model set to evaluation mode.")
 
 
     def save_network(self, filepath, device='cpu'):
@@ -133,7 +135,7 @@ class SimpleNN(torch.nn.Module):
         
         # Move model to CPU for saving (optional, saves GPU memory)
         original_device = next(self.parameters()).device
-        self.cpu()
+        #self.cpu()
         
         # Save the state dict
         torch.save({
@@ -145,7 +147,7 @@ class SimpleNN(torch.nn.Module):
         print(f"Network saved to {filepath}")
         
         # Move model back to original device
-        self.to(original_device)
+        #self.to(original_device)
 
 
 def load_network(filepath, device='cpu'):